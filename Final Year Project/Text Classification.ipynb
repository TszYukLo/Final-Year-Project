{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb112c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/waikinlam/miniforge3/envs/fyp/lib/python3.8/site-packages (3.5.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/waikinlam/miniforge3/envs/fyp/lib/python3.8/site-packages (from matplotlib) (4.33.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/waikinlam/miniforge3/envs/fyp/lib/python3.8/site-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/waikinlam/miniforge3/envs/fyp/lib/python3.8/site-packages (from matplotlib) (1.21.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/waikinlam/miniforge3/envs/fyp/lib/python3.8/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/waikinlam/miniforge3/envs/fyp/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/waikinlam/miniforge3/envs/fyp/lib/python3.8/site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/waikinlam/miniforge3/envs/fyp/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/waikinlam/miniforge3/envs/fyp/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/waikinlam/miniforge3/envs/fyp/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e6ea3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "import data_collection\n",
    "import tokenization\n",
    "import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9095fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting data\n",
    "data_from_j = open('dataset_for_domain.json', 'r')\n",
    "json_data_dic = json.loads(data_from_j.read())\n",
    "data_from_j.close()\n",
    "\n",
    "dialogue = []\n",
    "for data in json_data_dic:\n",
    "    dialogue.append(data['dialogue'])\n",
    "\n",
    "transcript_label_pair = []\n",
    "for conversation in dialogue:\n",
    "    for turn in conversation:\n",
    "        transcript_label_pair.append({'transcript': turn['transcript'], 'turn_label': turn['turn_label']})\n",
    "\n",
    "price_range, name, time, food, ignore_word = [], [], [], [], []\n",
    "categories_message_with_label = []\n",
    "for pair in transcript_label_pair:\n",
    "    labeled_transcript = pair['transcript']\n",
    "    label_list = pair['turn_label']\n",
    "    categories_turn_label = [0, 0, 0, 0, 0] # price, name, time, food, useless\n",
    "    for label in label_list:\n",
    "        if label[0] == 'restaurant-pricerange' or label[0] == 'hotel-pricerange':\n",
    "            price_range.append({'transcript': labeled_transcript, 'label': label[1], 'key_label': [1, 0, 0, 0, 0]})\n",
    "            categories_turn_label[0] = 1\n",
    "        elif label[0] == 'hotel-name' or label[0] == 'restaurant-name' or label[0] == 'taxi-departure'\\\n",
    "                or label[0] == 'taxi-departure' or label[0] == 'taxi-destination' or label[0] == 'attraction-name'\\\n",
    "                or label[0] == 'train-departure' or label[0] == 'train-destination':\n",
    "            name.append({'transcript': labeled_transcript, 'label': label[1], 'key_label': [0, 1, 0, 0, 0]})\n",
    "            categories_turn_label[1] = 1\n",
    "        elif label[0] == 'restaurant-book time' or label[0] == 'train-arriveby' or label[0] == 'train-leaveat'\\\n",
    "                or label[0] == 'taxi-arriveby' or label[0] == 'taxi-leaveat':\n",
    "            time.append({'transcript': labeled_transcript, 'label': label[1], 'key_label': [0, 0, 1, 0, 0]})\n",
    "            categories_turn_label[2] = 1\n",
    "        elif label[0] == 'restaurant-food':\n",
    "            food.append({'transcript': labeled_transcript, 'label': label[1], 'key_label': [0, 0, 0, 1, 0]})\n",
    "            categories_turn_label[3] = 1\n",
    "    categories_message_with_label.append({'transcript': labeled_transcript, 'categories_label': categories_turn_label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build categories_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 13   7 149 ...   0   0   0]\n",
      " [  2  32  19 ...   0   0   0]\n",
      " [  2  32  19 ...   0   0   0]\n",
      " ...\n",
      " [  2  32 529 ...  58  22  52]\n",
      " [  2  32 529 ...  58  22  52]\n",
      " [  2  32 529 ...  58  22  52]]\n",
      "[[ 87]\n",
      " [ 87]\n",
      " [133]\n",
      " ...\n",
      " [ 91]\n",
      " [ 20]\n",
      " [ 13]]\n",
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 12:17:56.340114: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-24 12:17:56.340255: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " transcript_input (InputLayer)  [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " word_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 25, 8)        31528       ['transcript_input[0][0]']       \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 4)         15764       ['word_input[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 64)           10496       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 8)            416         ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 72)           0           ['bidirectional[0][0]',          \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 8)            584         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " stage_output (Dense)           (None, 5)            45          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 58,833\n",
      "Trainable params: 58,833\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 12:17:56.879114: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-24 12:17:58.804114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-24 12:17:59.179316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-24 12:17:59.179903: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-24 12:17:59.190156: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-24 12:17:59.600946: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-24 12:17:59.616027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-24 12:17:59.631502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# train categories model\n",
    "# preprocessing\n",
    "print(\"Build categories_model\")\n",
    "message_without_empty_label = []\n",
    "for pair in categories_message_with_label:\n",
    "    if pair['categories_label'] != [0, 0, 0, 0]:\n",
    "        message_without_empty_label.append(pair)\n",
    "\n",
    "categories_train = message_without_empty_label[4000:]\n",
    "categories_test = message_without_empty_label[:4000]\n",
    "categories_train_message, categories_train_label = [], []\n",
    "for categories_pair in categories_train:\n",
    "    categories_train_message.append(categories_pair['transcript'])\n",
    "    categories_train_label.append(categories_pair['categories_label'])\n",
    "categories_test_message, categories_test_label = [], []\n",
    "for categories_pair in categories_test:\n",
    "    categories_test_message.append(categories_pair['transcript'])\n",
    "    categories_test_label.append(categories_pair['categories_label'])\n",
    "\n",
    "# Dictionary    !!! Tokenizer !!!\n",
    "tokenizer, padded_tokenized_message_train, padded_tokenized_message_test = \\\n",
    "    tokenization.tokenize_message(categories_train_message, categories_test_message)\n",
    "categories_train_dataset = [padded_tokenized_message_train, categories_train_label]\n",
    "categories_test_dataset = [padded_tokenized_message_test, categories_test_label]\n",
    "# train model part\n",
    "# train_model.categories_model(tokenizer, categories_train_dataset, categories_test_dataset)\n",
    "\n",
    "# keyboard model\n",
    "# show data size\n",
    "price_range_train, price_range_test = price_range[1000:], price_range[:1000]\n",
    "name_train, name_test = name[2000:], name[:2000]\n",
    "time_train, time_test = time[900:], time[:900]\n",
    "food_train, food_test = food[1000:], food[:1000]\n",
    "# split dataset to train and test\n",
    "train_dataset = price_range_train + name_train + time_train + food_train\n",
    "test_dataset = price_range_test + name_test + time_test + food_test\n",
    "\n",
    "total_data = price_range_train + name_train + time_train + food_train \\\n",
    "             + price_range_test + name_test + time_test + food_test\n",
    "\n",
    "# collect word is not useful for fifth tag\n",
    "key_word, target_word = [], []\n",
    "for element in total_data:  # collect all the keyword\n",
    "    if element['label'] not in key_word:\n",
    "        key_word.append(element['label'])\n",
    "all_transcript, useless = [], []\n",
    "for element in total_data:  # add word to target_word if the word not in keyword\n",
    "    all_transcript.append(element['transcript'])\n",
    "for sentence in all_transcript:\n",
    "    sentence_word_list = sentence.split(' ')\n",
    "    for word in sentence_word_list:\n",
    "        if word not in key_word:\n",
    "            useless.append({'transcript': sentence, 'label': word, 'key_label': [0, 0, 0, 0, 1]})\n",
    "\n",
    "# add useless in train and test\n",
    "train_dataset = price_range_train + name_train + time_train + food_train + useless[5000:25000]\n",
    "test_dataset = price_range_test + name_test + time_test + food_test + useless[:5000]\n",
    "\n",
    "hold_transcript, key_word, key_label = [], [], []\n",
    "for turn in train_dataset:\n",
    "    hold_transcript.append(turn['transcript'])  # input data\n",
    "    key_word.append(turn['label'])  # input data\n",
    "    key_label.append(turn['key_label'])  # output data\n",
    "\n",
    "#   tokenize the word in sentences\n",
    "print(hold_transcript)\n",
    "tokenized_transcript = tokenizer.texts_to_sequences(hold_transcript)\n",
    "tokenized_key_word = tokenizer.texts_to_sequences(key_word)\n",
    "padded_tokenized_transcript = pad_sequences(tokenized_transcript, maxlen=25, padding='post', truncating='post')\n",
    "padded_tokenized_key_word = pad_sequences(tokenized_key_word, maxlen=1, padding='post', truncating='post')\n",
    "\n",
    "# model structure\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "transcript_input = tf.keras.Input(shape=(25,), name=\"transcript_input\")\n",
    "word_input = tf.keras.Input(shape=(1,), name=\"word_input\")\n",
    "transcript_features = tf.keras.layers.Embedding(vocab_size, 8)(transcript_input)\n",
    "word_features = tf.keras.layers.Embedding(vocab_size, 4)(word_input)\n",
    "transcript_features = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(transcript_features)\n",
    "word_features = tf.keras.layers.LSTM(8)(word_features)\n",
    "combine_layer = tf.keras.layers.concatenate([transcript_features, word_features])\n",
    "control_range_layer = tf.keras.layers.Dense(8, activation='linear')(combine_layer)\n",
    "key_word_output = tf.keras.layers.Dense(5, name=\"stage_output\", activation='sigmoid')(control_range_layer)\n",
    "word_classify_model = tf.keras.Model(\n",
    "    inputs=[transcript_input, word_input],\n",
    "    outputs=[key_word_output],\n",
    ")\n",
    "word_classify_model.compile(loss=['binary_crossentropy'], optimizer='adam', metrics=['acc'])\n",
    "print(word_classify_model.summary())\n",
    "tf.keras.utils.plot_model(word_classify_model, 'transcript_model.png', show_shapes=True)\n",
    "\n",
    "history = word_classify_model.fit({\"transcript_input\": padded_tokenized_transcript, \"word_input\": padded_tokenized_key_word},\n",
    "                                  np.array(key_label), epochs=3,\n",
    "                                  validation_data=({\"transcript_input\": padded_tokenized_transcript,\n",
    "                                            \"word_input\": padded_tokenized_key_word},\n",
    "                                           np.array(key_label)), verbose=2)\n",
    "train_model.plot_model_accurate(history)  # plot graph\n",
    "# word_classify_model.save('transcript_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab91e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "sentence = [\"hello, I would like to book a cheap hotel\", \"Book a table at 16:00 University\",\n",
    "            \"hello, book a table at 16:00\", \"Want to find some japanese food\",\n",
    "            \"Want to find some japanese food\", \"Want to find some japanese food\"]\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "\n",
    "# input layer data text\n",
    "padded = pad_sequences(sequences, maxlen=25, padding='post', truncating='post')\n",
    "word = ['cheap', 'University', '16:00', 'japanese', 'some', 'to']\n",
    "word = tokenizer.texts_to_sequences(word)\n",
    "padded_word = pad_sequences(word, maxlen=1, padding='post', truncating='post')\n",
    "\n",
    "print(padded)\n",
    "print(padded_word)\n",
    "\n",
    "print(\n",
    "    word_classify_model.predict({\"transcript_input\": padded, \"word_input\": padded_word})\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c2f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
